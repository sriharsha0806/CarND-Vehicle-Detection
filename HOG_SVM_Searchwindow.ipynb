{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "# The goals/steps of this project are the following\n",
    "* Perform a Histogram of Oriented Gradients(HOG) feature extraction on a labeled training set of images and train a classifier Linear SVM classifier\n",
    "* Optionally you can also apply a color tranform and append binned color features, as well as histograms of color, to your HOG feature vector.\n",
    "* Note: for those first two steps don't forget to normalize your features and randomize a selection for training and testing.\n",
    "* Implement a sliding-window technique and use your trained classifier to search for vehicles in images.\n",
    "* Run your pipeline on a video stream(start with test_video.mp4 and later implement on full project_video.mp4) and create a heat map of recurring detections frame by frame to reject outliers and follow detected vehicles.\n",
    "* Estimate a bounding box for vehicles detected."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "import matplotlib.image as mpimg\n",
    "from matplotlib import pyplot as plt\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "import glob\n",
    "from skimage.feature import hog\n",
    "import time\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from skimage.feature import hog\n",
    "from helper import *\n",
    "from sklearn.model_selection import train_test_split\n",
    "from scipy.ndimage.measurements import label\n",
    "import time\n",
    "from moviepy.editor import VideoFileClip\n",
    "from IPython.display import HTML\n",
    "%matplotlib inline\n",
    "%matplotlib qt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8792\n",
      "8968\n"
     ]
    }
   ],
   "source": [
    "# Loading the car and notcar data\n",
    "vehicles = glob.glob('vehicles/**/*.png')\n",
    "non_vehicles = glob.glob('non-vehicles/**/*.png')\n",
    "print(len(vehicles))\n",
    "print(len(non_vehicles))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Read a color image\n",
    "img = cv2.imread(\"cutout1.jpg\")\n",
    "# Select a small fraction of pixels to plot by subsampling it\n",
    "scale = max(img.shape[0], img.shape[1], 64) / 64  # at most 64 rows and columns\n",
    "img_small = cv2.resize(img, (np.int(img.shape[1] / scale), np.int(img.shape[0] / scale)), interpolation=cv2.INTER_NEAREST)\n",
    "\n",
    "# Convert subsampled image to desired color space(s)\n",
    "img_small_RGB = cv2.cvtColor(img_small, cv2.COLOR_BGR2RGB)  # OpenCV uses BGR, matplotlib likes RGB\n",
    "img_small_HSV = cv2.cvtColor(img_small, cv2.COLOR_BGR2HSV)\n",
    "img_small_LUV = cv2.cvtColor(img_small, cv2.COLOR_BGR2LUV)\n",
    "img_small_HLS = cv2.cvtColor(img_small, cv2.COLOR_BGR2HLS)\n",
    "img_small_YUV = cv2.cvtColor(img_small, cv2.COLOR_BGR2YUV)\n",
    "img_small_YCrCb = cv2.cvtColor(img_small, cv2.COLOR_BGR2YCrCb)\n",
    "img_small_rgb = img_small_RGB / 255.  # scaled to [0, 1], only for plotting\n",
    "\n",
    "# Plot and show\n",
    "plot3d(img_small_RGB, img_small_rgb)\n",
    "plt.title('RGB_colorspace')\n",
    "plt.show()\n",
    "\n",
    "plot3d(img_small_HSV, img_small_rgb, axis_labels=list(\"HSV\"))\n",
    "plt.title('HSV_colorspace')\n",
    "plt.show()\n",
    "\n",
    "plot3d(img_small_LUV, img_small_rgb, axis_labels=list(\"LUV\"))\n",
    "plt.title('LUV_colorspace')\n",
    "plt.show()\n",
    "\n",
    "plot3d(img_small_HLS, img_small_rgb, axis_labels=list(\"HLS\"))\n",
    "plt.title('HLS_colorspace')\n",
    "plt.show()\n",
    "\n",
    "plot3d(img_small_YUV, img_small_rgb, axis_labels=list(\"YUV\"))\n",
    "plt.title('YUV_colorspace')\n",
    "plt.show()\n",
    "\n",
    "plot3d(img_small_YCrCb, img_small_rgb, axis_labels=list(\"YCrCb\"))\n",
    "plt.title('YCrCb_colorspace')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# plot positives and negatives\n",
    "fig, axs =plt.subplots(8,8, figsize=(16,16))\n",
    "fig.subplots_adjust(hspace=.2,wspace=.001)\n",
    "axs = axs.ravel()\n",
    "\n",
    "for i in np.arange(32):\n",
    "    img = cv2.imread(vehicles[np.random.randint(0,len(vehicles))])\n",
    "    img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "    axs[i].axis('off')\n",
    "    axs[i].set_title('car', fontsize=32)\n",
    "    axs[i].imshow(img)\n",
    "for i in np.arange(32,64):\n",
    "    img = cv2.imread(non_vehicles[np.random.randint(0,len(non_vehicles))])\n",
    "    img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "    axs[i].axis('off')\n",
    "    axs[i].set_title('notcar', fontsize=32)\n",
    "    axs[i].imshow(img)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "hog() function\n",
    "takes in a single color channel or grayscaled image as input, parameters are orientations, pixel_per_cell and cells_per_block\n",
    "The number of orientations is specified as an integer, and represents the number of orientaion bins that the gradient information will be split into the histogram. Typical value ranges 6 to 12.\n",
    "The pixels_per_cell parameters specifies the cell size over which gradient histogram is computed. This parameter is passed as a 2 tuple so you could have differnet cell sizes in x and y, but cells are commonly chosen to be squre\n",
    "The cells_per_block parameter is also passed as a 2-tuple, and specified the local area over which the histogram counts in a given cell will be normalized. Block noramlization is not necessarily required, but generally leads to a more robust eature set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "pos_img = cv2.imread(vehicles[np.random.randint(0, len(vehicles))])\n",
    "pos_gray = cv2.cvtColor(pos_img, cv2.COLOR_BGR2GRAY)\n",
    "# Define HOG parameters\n",
    "orient = 9\n",
    "pix_per_cell = 8\n",
    "cell_per_block = 2\n",
    "# Call our function with vis=True to see an image output\n",
    "features, hog_image1 = get_hog_features(pos_gray, orient, \n",
    "                        pix_per_cell, cell_per_block, \n",
    "                        vis=True, feature_vec=False)\n",
    "\n",
    "\n",
    "# Plot the examples\n",
    "\n",
    "fig = plt.figure()\n",
    "plt.subplot(121)\n",
    "plt.imshow(pos_img, cmap='gray')\n",
    "plt.title('Example Car Image')\n",
    "plt.subplot(122)\n",
    "plt.imshow(hog_image1, cmap='gray')\n",
    "plt.title('HOG Visualization')\n",
    "\n",
    "neg_img = cv2.imread(non_vehicles[np.random.randint(0,len(non_vehicles))])\n",
    "neg_gray = cv2.cvtColor(neg_img, cv2.COLOR_BGR2GRAY)\n",
    "features, hog_image2 = get_hog_features(neg_gray, orient, \n",
    "                        pix_per_cell, cell_per_block, \n",
    "                        vis=True, feature_vec=False)\n",
    "\n",
    "\n",
    "# Plot the examples\n",
    "\n",
    "fig = plt.figure()\n",
    "plt.subplot(121)\n",
    "plt.imshow(neg_img, cmap='gray')\n",
    "plt.title('Example of non Car Image')\n",
    "plt.subplot(122)\n",
    "plt.imshow(hog_image2, cmap='gray')\n",
    "plt.title('HOG Visualization')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8792 8968\n"
     ]
    }
   ],
   "source": [
    "cars = []\n",
    "notcars = []\n",
    "for image in vehicles:\n",
    "    cars.append(image)\n",
    "for image in non_vehicles:\n",
    "    notcars.append(image)\n",
    "print(len(cars),len(notcars))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7f2e93b91668>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "img = cv2.imread(cars[1000])\n",
    "plt.imshow(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[360, 720]\n",
      "8792\n",
      "8968\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "### TODO: Tweak these parameters and see how the results change.\n",
    "color_space = 'RGB' # RGB # Can be RGB, HSV, LUV, HLS, YUV, YCrCb\n",
    "orient = 8 #9 #8 # HOG orientations\n",
    "pix_per_cell = 8 # 2 # HOG pixels per cell\n",
    "cell_per_block = 2 # HOG pixels per cell\n",
    "hog_channel = 'ALL' # Can be 0, 1, 2, or \"ALL\"\n",
    "spatial_size = (16,16) # Spatial features on or off\n",
    "hist_bins = 32 # Number of histogram bins\n",
    "spatial_feat = True # Spatial features on or off\n",
    "hist_feat = True # Histogram features on or off\n",
    "hog_feat = True # HOG features on or off\n",
    "\"\"\"\n",
    "test_img = mpimg.imread('test_images/test6.jpg')\n",
    "img_shape = test_img.shape\n",
    "color_space = 'RGB' # Can be RGB, HSV, LUV, HLS, YUV, YCrCb\n",
    "orient = 8  # HOG orientations\n",
    "pix_per_cell = 8 # HOG pixels per cell\n",
    "cell_per_block = 2 # HOG cells per block\n",
    "hog_channel = 0 # Can be 0, 1, 2, or \"ALL\"\n",
    "spatial_size = (16, 16) # Spatial binning dimensions\n",
    "hist_bins = 32    # Number of histogram bins\n",
    "spatial_feat = True # Spatial features on or off\n",
    "hist_feat = True # Histogram features on or off\n",
    "hog_feat = True # HOG features on or off\n",
    "y_start_stop = [int(img_shape[0] * 0.5), img_shape[0]] # Min and max in y to search in slide_window()\n",
    "print(y_start_stop)\n",
    "car_features = extract_features(cars, color_space=color_space, \n",
    "                        spatial_size=spatial_size, hist_bins=hist_bins, \n",
    "                        orient=orient, pix_per_cell=pix_per_cell, \n",
    "                        cell_per_block=cell_per_block, \n",
    "                        hog_channel=hog_channel, spatial_feat=spatial_feat, \n",
    "                        hist_feat=hist_feat, hog_feat=hog_feat)\n",
    "notcar_features = extract_features(notcars, color_space=color_space, \n",
    "                        spatial_size=spatial_size, hist_bins=hist_bins, \n",
    "                        orient=orient, pix_per_cell=pix_per_cell, \n",
    "                        cell_per_block=cell_per_block, \n",
    "                        hog_channel=hog_channel, spatial_feat=spatial_feat, \n",
    "                        hist_feat=hist_feat, hog_feat=hog_feat)\n",
    "\n",
    "print(len(car_features))\n",
    "print(len(notcar_features))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using: 8 orientations 8 pixels per cell and 2 cells per block\n",
      "Feature vector length: 2432\n",
      "698.36 Seconds to train SVC...\n",
      "Test Accuracy of SVC =  0.9924\n"
     ]
    }
   ],
   "source": [
    "X = np.vstack((car_features, notcar_features)).astype(np.float64)\n",
    "# Fit a per-column scaler\n",
    "X_scaler = StandardScaler().fit(X)\n",
    "# Apply the scaler to X\n",
    "scaled_X = X_scaler.transform(X)\n",
    "# Define the labels vector\n",
    "y = np.hstack((np.ones(len(car_features)), np.zeros(len(notcar_features))))\n",
    "# Split up data into randomized training and test sets\n",
    "rand_state = np.random.randint(0,100)\n",
    "X_train, X_test, y_train, y_test = train_test_split(scaled_X, y, test_size=0.2, random_state=rand_state)\n",
    "\n",
    "print('Using:',orient,'orientations',pix_per_cell,\n",
    "    'pixels per cell and', cell_per_block,'cells per block')\n",
    "print('Feature vector length:', len(X_train[0]))\n",
    "# Use a linear SVC \n",
    "svc = SVC(C=1.0, probability=True)\n",
    "# Check the training time for the SVC\n",
    "t=time.time()\n",
    "svc.fit(X_train, y_train)\n",
    "t2 = time.time()\n",
    "print(round(t2-t, 2), 'Seconds to train SVC...')\n",
    "# Check the score of the SVC\n",
    "print('Test Accuracy of SVC = ', round(svc.score(X_test, y_test), 4))\n",
    "# Check the prediction time for a single sample\n",
    "t=time.time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.  0.  0.  0.  0.  1.  0.  1.  0.  0.  0.  0.  1.  0.  0.]\n",
      "[ 1.  0.  0.  0.  0.  1.  0.  1.  0.  0.  0.  0.  1.  0.  0.]\n"
     ]
    }
   ],
   "source": [
    "# Testing\n",
    "n=15\n",
    "print(svc.predict(X_test[100:100+n]))\n",
    "print(y_test[100:100+n])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def draw_bounding_boxes(image):\n",
    "    draw_image = np.copy(image)\n",
    "    hot_windows = []\n",
    "    \n",
    "    for window_size in [(96, 96), (120, 120)]:\n",
    "        windows = slide_window(image, x_start_stop=[int(image.shape[1]/2), image.shape[1]], y_start_stop=y_start_stop, \n",
    "                            xy_window=window_size, xy_overlap=(0.9, 0.9))\n",
    "\n",
    "        hot_windows.extend(search_windows(image, windows, svc, X_scaler, color_space=color_space, \n",
    "                                spatial_size=spatial_size, hist_bins=hist_bins, \n",
    "                                orient=orient, pix_per_cell=pix_per_cell, \n",
    "                                cell_per_block=cell_per_block, \n",
    "                                hog_channel=hog_channel, spatial_feat=spatial_feat, \n",
    "                                hist_feat=hist_feat, hog_feat=hog_feat))                      \n",
    "\n",
    "    window_img = draw_boxes(draw_image, hot_windows, color=(0, 0, 255), thick=6)                    \n",
    "#     plt.imshow(window_img)\n",
    "#     plt.show()\n",
    "    \n",
    "    heat = np.zeros_like(image[:,:,0]).astype(np.float)\n",
    "\n",
    "    add_heat(heat, hot_windows)\n",
    "\n",
    "    final_map = np.clip(heat , 0, 255)\n",
    "    \n",
    "#     plt.imshow(final_map, cmap='hot')\n",
    "#     plt.show()\n",
    "    \n",
    "    heatmap = apply_threshold(heat, 2)\n",
    "    labels = label(heatmap)\n",
    "    \n",
    "    # Draw bounding boxes on a copy of the image\n",
    "    draw_img = draw_labeled_bboxes(np.copy(image), labels)\n",
    "    # Display the image\n",
    "#     plt.imshow(draw_img)\n",
    "#     plt.show()\n",
    "    return draw_img\n",
    "    \n",
    "image_name = glob.glob(\"test_images/*\")[2]\n",
    "image = plt.imread(image_name)\n",
    "plt.figure()\n",
    "plt.imshow(image)\n",
    "plt.show()\n",
    "\n",
    "# image = mpimg.imread('bbox-example-image.jpg')\n",
    "draw_img = draw_bounding_boxes(image)\n",
    "plt.figure()\n",
    "plt.imshow(draw_img)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "img = mpimg.imread('test_images/test6.jpg')\n",
    "img_shape = img.shape\n",
    "img_copy = np.copy(img)\n",
    "y_start_stop = [int(img_shape[0] * 0.5), img_shape[0]] \n",
    "print(y_start_stop)\n",
    "boxes = []\n",
    "for window_size in [(96, 96), (120, 120)]:\n",
    "    windows = slide_window(image, x_start_stop=[int(image.shape[1]/2), image.shape[1]], y_start_stop=y_start_stop, \n",
    "                            xy_window=window_size, xy_overlap=(0.9, 0.9))\n",
    "\n",
    "    boxes.extend(search_windows(image, windows, svc, X_scaler, color_space=color_space, \n",
    "                                spatial_size=spatial_size, hist_bins=hist_bins, \n",
    "                                orient=orient, pix_per_cell=pix_per_cell, \n",
    "                                cell_per_block=cell_per_block, \n",
    "                                hog_channel=hog_channel, spatial_feat=spatial_feat, \n",
    "                                hist_feat=hist_feat, hog_feat=hog_feat))                      \n",
    "\n",
    "window_img = draw_boxes(img_copy, boxes, color=(0, 0, 255), thick=6)                    \n",
    "plt.imshow(window_img)\n",
    "plt.show()\n",
    "heat = np.zeros_like(image[:,:,0]).astype(np.float)\n",
    "add_heat(heat, boxes)\n",
    "final_map = np.clip(heat , 0, 255)\n",
    "plt.imshow(final_map, cmap='hot')\n",
    "plt.show()\n",
    "heatmap = apply_threshold(heat, 2)\n",
    "labels = label(heatmap)\n",
    "# Draw bounding boxes on a copy of the image\n",
    "draw_img = draw_labeled_bboxes(np.copy(image), labels)\n",
    "# Display the image\n",
    "plt.imshow(draw_img)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "from moviepy.editor import VideoFileClip\n",
    "from IPython.display import HTML"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def process(image):\n",
    "    return draw_bounding_boxes(image)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "for image_name in glob.glob(\"test_images/*\"):\n",
    "    test_img = plt.imread(image_name)\n",
    "    test_img = process(test_img)\n",
    "    plt.imshow(test_img)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[MoviePy] >>>> Building video p5.mp4\n",
      "[MoviePy] Writing video p5.mp4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  8%|▊         | 104/1261 [1:15:04<14:12:14, 44.20s/it]"
     ]
    }
   ],
   "source": [
    "output = 'p5.mp4'\n",
    "clip1 = VideoFileClip(\"./project_video.mp4\")\n",
    "output_clip = clip1.fl_image(process) #NOTE: this function expects color images!!\n",
    "%time output_clip.write_videofile(output, audio=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  },
  "widgets": {
   "state": {},
   "version": "1.1.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
